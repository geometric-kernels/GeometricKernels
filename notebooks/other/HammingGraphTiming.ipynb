{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this in Google Colab, uncomment the following line\n",
    "# !pip install geometric_kernels\n",
    "\n",
    "# If you want to use a version of the library from a specific branch on GitHub,\n",
    "# say, from the \"devel\" branch, uncomment the line below instead\n",
    "# !pip install \"git+https://github.com/geometric-kernels/GeometricKernels@devel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Speed Improvements on Hypercube/Hamming Graphs\n",
    "\n",
    "This notebook benchmarks two methods for the `HypercubeGraph` and `HammingGraph` spaces with $\\nu = \\infty$:\n",
    "\n",
    "1. \"slow\" method — based on the addition theorem presented on this [documentation page](https://geometric-kernels.github.io/GeometricKernels/theory/hamming_graph.html),\n",
    "2. \"fast\" method — based on the closed-form equations discusssed in [Kondor and Lafferty (2002)](https://people.cs.uchicago.edu/~risi/papers/diffusion-kernels.pdf) or [Doumont et al. (2025)](https://arxiv.org/pdf/2510.26633).\n",
    "\n",
    "Moreover, we also double-check whether the different methods lead to equal kernels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (geometric_kernels): Numpy backend is enabled. To enable other backends, don't forget to `import geometric_kernels.*backend name*`.\n",
      "INFO (geometric_kernels): We may be suppressing some logging of external libraries. To override the logging policy, call `logging.basicConfig`.\n",
      "/opt/miniconda3/envs/geometrik/lib/python3.11/site-packages/spherical_harmonics/fundamental_set.py:21: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from geometric_kernels.kernels import MaternKernelHammingGraph\n",
    "from geometric_kernels.kernels.karhunen_loeve import MaternKarhunenLoeveKernel\n",
    "from geometric_kernels.spaces import HammingGraph, HypercubeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Configuration\n",
    "SPACE_DIM = 20  # dimensionality of the space\n",
    "N_CAT = 5  # number of categories (alphabet size) for Hamming graph\n",
    "N_SAMPLES = 3000  # number of points to evalute the kernels on\n",
    "N_RUNS = 10  # number of seeds to average over\n",
    "LENGTHSCALES = [1.0, 5.0, 10.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(space, n, seed_offset=0):\n",
    "    key1 = np.random.RandomState(1234 + seed_offset)\n",
    "    key2 = np.random.RandomState(5678 + seed_offset)\n",
    "    _, X1 = space.random(key1, n)\n",
    "    _, X2 = space.random(key2, n)\n",
    "    return X1, X2\n",
    "\n",
    "\n",
    "def run_benchmark(space, kernel_type, lengthscales, n_samples, n_runs, space_dim):\n",
    "    results = {\"times\": defaultdict(list), \"kernels\": {}}\n",
    "\n",
    "    for lengthscale in lengthscales:\n",
    "        for run_idx in range(n_runs):\n",
    "            if kernel_type == \"fast\":\n",
    "                kernel = MaternKernelHammingGraph(space, num_levels=space_dim + 1)\n",
    "            else:\n",
    "                kernel = MaternKarhunenLoeveKernel(space, num_levels=space_dim + 1)\n",
    "\n",
    "            X1, X2 = generate_data(space, n_samples, seed_offset=run_idx * 1)\n",
    "            params = dict(nu=np.array([np.inf]), lengthscale=np.array([lengthscale]))\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            K = kernel.K(params, X1, X2)\n",
    "            elapsed = time.perf_counter() - start\n",
    "\n",
    "            results[\"times\"][lengthscale].append(elapsed)\n",
    "            if run_idx == 0:\n",
    "                results[\"kernels\"][lengthscale] = K\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results(fast_results, slow_results, lengthscales, space_name):\n",
    "    print(f\"\\n{'='*80}\\n{space_name}\\n{'='*80}\")\n",
    "\n",
    "    for ls in lengthscales:\n",
    "        fast_mean = np.mean(fast_results[\"times\"][ls])\n",
    "        slow_mean = np.mean(slow_results[\"times\"][ls])\n",
    "        speedup = slow_mean / fast_mean\n",
    "        is_equal = np.allclose(fast_results[\"kernels\"][ls], slow_results[\"kernels\"][ls])\n",
    "\n",
    "        print(\n",
    "            f\"Lengthscale {ls:5.1f}: Fast={fast_mean:.4f}s | Slow={slow_mean:.4f}s | \"\n",
    "            f\"Speedup={speedup:.2f}x | Equal={is_equal}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "HYPERCUBE GRAPH\n",
      "================================================================================\n",
      "Lengthscale   1.0: Fast=0.6992s | Slow=1.3529s | Speedup=1.94x | Equal=True\n",
      "Lengthscale   5.0: Fast=0.6834s | Slow=1.3563s | Speedup=1.98x | Equal=True\n",
      "Lengthscale  10.0: Fast=0.7838s | Slow=1.3482s | Speedup=1.72x | Equal=True\n",
      "Lengthscale  20.0: Fast=0.7434s | Slow=1.3582s | Speedup=1.83x | Equal=True\n",
      "\n",
      "================================================================================\n",
      "HAMMING GRAPH\n",
      "================================================================================\n",
      "Lengthscale   1.0: Fast=0.6942s | Slow=1.3436s | Speedup=1.94x | Equal=True\n",
      "Lengthscale   5.0: Fast=0.8381s | Slow=1.3142s | Speedup=1.57x | Equal=True\n",
      "Lengthscale  10.0: Fast=0.7756s | Slow=1.3819s | Speedup=1.78x | Equal=True\n",
      "Lengthscale  20.0: Fast=0.6543s | Slow=1.3453s | Speedup=2.06x | Equal=True\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Running...\")\n",
    "print(\"\")\n",
    "\n",
    "# HypercubeGraph\n",
    "graph = HypercubeGraph(SPACE_DIM)\n",
    "fast_results = run_benchmark(graph, \"fast\", LENGTHSCALES, N_SAMPLES, N_RUNS, SPACE_DIM)\n",
    "slow_results = run_benchmark(graph, \"slow\", LENGTHSCALES, N_SAMPLES, N_RUNS, SPACE_DIM)\n",
    "print_results(fast_results, slow_results, LENGTHSCALES, \"HYPERCUBE GRAPH\")\n",
    "\n",
    "# HammingGraph\n",
    "hamming_graph = HammingGraph(SPACE_DIM, N_CAT)\n",
    "fast_results = run_benchmark(\n",
    "    hamming_graph, \"fast\", LENGTHSCALES, N_SAMPLES, N_RUNS, SPACE_DIM\n",
    ")\n",
    "slow_results = run_benchmark(\n",
    "    hamming_graph, \"slow\", LENGTHSCALES, N_SAMPLES, N_RUNS, SPACE_DIM\n",
    ")\n",
    "print_results(fast_results, slow_results, LENGTHSCALES, \"HAMMING GRAPH\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you are using hypercube or Hamming graphs from GeometricKernels, please consider citing\n",
    "\n",
    "```\n",
    "@article{mostowsky2024,\n",
    "      title = {The GeometricKernels Package: Heat and Matérn Kernels for Geometric Learning on Manifolds, Meshes, and Graphs},\n",
    "      author = {Peter Mostowsky and Vincent Dutordoir and Iskander Azangulov and Noémie Jaquier and Michael John Hutchinson and Aditya Ravuri and Leonel Rozo and Alexander Terenin and Viacheslav Borovitskiy},\n",
    "      year = {2024},\n",
    "      journal = {arXiv:2407.08086},\n",
    "}\n",
    "```\n",
    "\n",
    "```\n",
    "@inproceedings{doumont2025,\n",
    "    title = {Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization},\n",
    "    author = {Colin Doumont and Victor Picheny and Viacheslav Borovitskiy and Henry Moss},\n",
    "    booktitle = {Advances in Neural Information Processing Systems},\n",
    "    year = {2025},\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometrik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
